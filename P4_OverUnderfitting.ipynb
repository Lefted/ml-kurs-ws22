{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisierung auf dem Titanic-Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinweis: Da das Notebook nur das Prinizip der Regularisierung zeigen soll, ist der ML-Worflow in diesem Notebook stark vereinfacht (d.h. kein Auff√ºllen von N/As, kein Feature-Scaling und keine kategorischen Features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # avoid slide-copy-warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare\n",
       "0         0       3  22.0      1      0   7.2500\n",
       "1         1       1  38.0      1      0  71.2833\n",
       "2         1       3  26.0      0      0   7.9250\n",
       "3         1       1  35.0      1      0  53.1000\n",
       "4         0       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selection = df[[\"Survived\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "df_selection = df_selection.dropna()\n",
    "df_selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_selection.drop(columns = [\"Survived\"])\n",
    "df_y = df_selection[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Ridge-Regularisierung\n",
    "1. Trainieren Sie eine Logistische Regression mit Ridge-Regularisierung (siehe [RidgeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)) mit $\\alpha =100$ auf den Trainingsdaten.\n",
    "2. Bestimmen Sie die Accuracy auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier(alpha=100.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=100.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier(alpha=100.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train logistic regression model with ridge regularization using RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier(alpha=100.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6713286713286714\n",
      "Feature weights:\n",
      "Pclass   -0.320888\n",
      "Age      -0.013431\n",
      "SibSp    -0.096943\n",
      "Parch     0.092842\n",
      "Fare      0.002719\n",
      "dtype: float64\n",
      "Sum of absolute weights:  0.5268232381956689\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, pred.round()))\n",
    "print(\"Feature weights:\")\n",
    "print(pd.Series(clf.coef_[0], index=X_train.columns))\n",
    "\n",
    "# q: why do we need to do clf.coef_[0] here?\n",
    "# a: clf.coef_ is a 2D array, with one row per class.\n",
    "#    we only have one class here, so we can just take the first row.\n",
    "\n",
    "print(\"Sum of absolute weights: \", np.sum(np.abs(clf.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Cross-Validation √ºber $\\alpha$\n",
    "1. F√ºhren Sie nun eine Cross-Validation mit Hilfe der Klasse [RidgeClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html) durch. Benutzen Sie daf√ºr die gleichen Werte f√ºr $\\alpha$ wie im Notebook [`4_OverUnderfitting.ipynb`](4_OverUnderfitting.ipynb) in Zelle 9.\n",
    "2. Bestimmen Sie die Accuracy auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 100 different values for Alpha\n",
      "Best Alpha:  6.579332246575679\n",
      "Best Score:  -0.19603116680069563\n",
      "Best Coefficients:  [-0.22209922 -0.00789843 -0.0631952   0.06616771  0.00086922]\n",
      "Sum of absolute weights:  0.3602297691243238\n"
     ]
    }
   ],
   "source": [
    "# import RidgeCV to find the best alpha value\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# create a list of alphas to try ranging from 0.1 to 10000\n",
    "alphas = np.logspace(-1, 4, 100)\n",
    "\n",
    "# q: what is -1 and 4 in np.logspace(-1, 4, 100)?\n",
    "# a: -1 and 4 are the exponents of 10, so we are trying alphas ranging from 0.1 to 10000\n",
    "\n",
    "\n",
    "print(f\"Testing {len(alphas)} different values for Alpha\")\n",
    "\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = RidgeCV(alphas=alphas, scoring='neg_mean_squared_error')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(\"Best Alpha: \", model.alpha_)\n",
    "print(\"Best Score: \", model.best_score_)\n",
    "print(\"Best Coefficients: \", model.coef_)\n",
    "print(\"Sum of absolute weights: \", np.sum(np.abs(model.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6853146853146853\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy on the test set\n",
    "pred = model.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, pred.round()))\n",
    "\n",
    "# q: why do we need to do pred.round() here?\n",
    "# a: pred is a continuous value, but we need to round it to 0 or 1 to compare it to y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3:  Lasso-Regularisierung\n",
    "F√ºr die Lasso-Regularisierung gibt es keine extra Unterklasse, da diese bei der Klasse `LogisitcRegression` √ºber den Parameter `penalty` eingestellt werden kann. Mit dem Parameter `penalty = \"l1\"` wird die Lasso-Regression verwendet.\n",
    "Der Regularisierungsfaktor $\\alpha$ wird in diesem Fall √ºber den Parameter `C` bestimmt, welcher den Default-Wert `C=1.0` hat:\n",
    "\n",
    "`LogisticRegression(max_iter=1000, penalty = \"l1\", C=1.0, solver=\"liblinear\")`\n",
    "\n",
    "Beachten Sie dabei:\n",
    "- F√ºr die Regression ist das zus√§tzliche Argument `solver=\"liblinear\"` n√∂tig, da der Standard-Optimierer nicht mit `L1` funktioniert.\n",
    "- Parameter `C` gibt die <ins>inverse</ins> St√§rke der Regularisierung an (Details siehe [hier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)).\n",
    "\n",
    "\n",
    "1. Trainieren Sie eine Logistische Regression mit Lasso-Regression f√ºr verschiedene Parameter `C`:\n",
    "    - den Default-Wert `C=1.0`.\n",
    "    - w√§hlen Sie `C` so, dass das Modell sehr stark regularisiert ist.\n",
    "    - w√§hlen Sie `C` so, dass das Modell keine Regularisierung hat.\n",
    "2. Vergleiche Sie die Ergebnisse dieser Modelle indem Sie:\n",
    "    - die Gewichte und deren Summe ausgeben (wie im Notebook [`4_OverUnderfitting.ipynb`](4_OverUnderfitting.ipynb)).\n",
    "    - die Accuracy auf den Testdaten ermitteln. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6923076923076923\n",
      "Feature weights:\n",
      "Pclass   -0.936605\n",
      "Age      -0.037646\n",
      "SibSp    -0.308796\n",
      "Parch     0.298062\n",
      "Fare      0.007298\n",
      "dtype: float64\n",
      "Sum of absolute weights:  1.5884066329559943\n",
      "Accuracy score:  0.6643356643356644\n",
      "Feature weights:\n",
      "Pclass    0.000000\n",
      "Age      -0.028366\n",
      "SibSp     0.000000\n",
      "Parch     0.000000\n",
      "Fare      0.016453\n",
      "dtype: float64\n",
      "Sum of absolute weights:  0.044819110820533595\n",
      "Accuracy score:  0.6853146853146853\n",
      "Feature weights:\n",
      "Pclass   -1.051885\n",
      "Age      -0.041738\n",
      "SibSp    -0.336227\n",
      "Parch     0.327037\n",
      "Fare      0.005961\n",
      "dtype: float64\n",
      "Sum of absolute weights:  1.7628477678030783\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression model with lasso regularization using LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# default C=1.0\n",
    "lassoReg = LogisticRegression(max_iter=1000, penalty='l1', C=1.0, solver='liblinear')\n",
    "\n",
    "lassoReg.fit(X_train, y_train)\n",
    "\n",
    "pred = lassoReg.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, pred.round()))\n",
    "print(\"Feature weights:\")\n",
    "print(pd.Series(lassoReg.coef_[0], index=X_train.columns))\n",
    "print(\"Sum of absolute weights: \", np.sum(np.abs(lassoReg.coef_)))\n",
    "\n",
    "# strong regularization (C=0.01)\n",
    "lassoReg = LogisticRegression(max_iter=1000, penalty='l1', C=0.01, solver='liblinear')\n",
    "\n",
    "lassoReg.fit(X_train, y_train)\n",
    "\n",
    "pred = lassoReg.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, pred.round()))\n",
    "print(\"Feature weights:\")\n",
    "print(pd.Series(lassoReg.coef_[0], index=X_train.columns))\n",
    "print(\"Sum of absolute weights: \", np.sum(np.abs(lassoReg.coef_)))\n",
    "\n",
    "# weak regularization (C=100)\n",
    "lassoReg = LogisticRegression(max_iter=1000, penalty='l1', C=100, solver='liblinear')\n",
    "\n",
    "lassoReg.fit(X_train, y_train)\n",
    "\n",
    "pred = lassoReg.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, pred.round()))\n",
    "print(\"Feature weights:\")\n",
    "print(pd.Series(lassoReg.coef_[0], index=X_train.columns))\n",
    "print(\"Sum of absolute weights: \", np.sum(np.abs(lassoReg.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 4. Cross-Validierung √ºber  `C`\n",
    "Ein guter Wert f√ºr `C` soll nun mit Hilfe der Methode `cross_val_score` gefunden werden. Ein Beispiel f√ºr diese Methode ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65217391, 0.73684211, 0.6754386 , 0.71929825, 0.71052632])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, penalty = \"l1\", C=1.0, solver=\"liblinear\")\n",
    "cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Methode f√ºhrt eine k-fold Cross-Validation auf den Trainingsdaten durch und gibt f√ºr jeden der k-folds den Score (in diesem Fall \"accuracy\") des Modell auf den jeweiligen Validierungsdaten zur√ºck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Berechnen Sie den Durchschnitt der R√ºckgabewerte von `cross_val_score` um f√ºr das gegebene `model` den durchschnittlichen Accuarcy-Score √ºber alle k-folds zu erhalten.\n",
    "2. Berechnen Sie f√ºr jeden der Werte $ C \\in [0.1, 0.2, ...,9.8, 9.9]$ den durchschnittlichen Accuarcy-Score.\n",
    "3. Trainieren Sie das Modell mit dem besten Wert f√ºr $C$ auf allen Trainingsdaten.\n",
    "4. Bestimmen Sie die Accuracy dieses Modells auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 99 different values for C\n",
      "Best C:  0.30000000000000004\n",
      "Best Score:  0.7216475972540046\n"
     ]
    }
   ],
   "source": [
    "# create a list of C ranging from 0.1 to 9.9\n",
    "Cs = np.arange(0.1, 10, 0.1)\n",
    "\n",
    "# q: what is 0.1 and 10 in np.arange(0.1, 10, 0.1)?\n",
    "# a: 0.1 and 10 are the start and end values, and 0.1 is the step size\n",
    "\n",
    "print(f\"Testing {len(Cs)} different values for C\")\n",
    "\n",
    "# create LogisticRegression model with l1 penalty and liblinear solver for each C\n",
    "best_C, best_score = 0, 0\n",
    "for C in Cs:\n",
    "\tmodel = LogisticRegression(max_iter=1000, penalty = \"l1\", C=C, solver=\"liblinear\")\n",
    "\tscores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\t\n",
    "\t# calculate mean of scores and compare to best score so far\n",
    "\tmean_score = np.mean(scores)\n",
    "\tif mean_score > best_score:\n",
    "\t\tbest_score = mean_score\n",
    "\t\tbest_C = C\n",
    "\t\n",
    "print(\"Best C: \", best_C)\n",
    "print(\"Best Score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "# train model with best C value\n",
    "model = LogisticRegression(max_iter=1000, penalty = \"l1\", C=best_C, solver=\"liblinear\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# determine accuracy on the test set\n",
    "pred = model.predict(X_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, pred.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c05a811d538a2b13f6a8e08fbeb3fd458bca6a94fd2685c1b9563894d3e17f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
